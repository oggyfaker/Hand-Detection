{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "folderPath ='/mnt/DeepLearning/hand/hand143_panopticdb/' #Put your local path here\n",
    "jsonPath = folderPath +'hands_v143_14817.json'\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (20,20)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "with open(jsonPath, 'r') as fid:\n",
    "    dat_all = json.load(fid)\n",
    "    data_all= dat_all['root']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data to folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "817"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data_all)) \n",
    "data_train = data_all[:13000]\n",
    "data_valid = data_all[13000:14000]\n",
    "data_test = data_all[14000:]\n",
    "len(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "path = \"/mnt/DeepLearning/hand/hand143_panopticdb/\"\n",
    "\n",
    "train_files = [file['img_paths'] for file in data_train] \n",
    "valid_files = [file['img_paths'] for file in data_valid] \n",
    "test_files = [file['img_paths'] for file in data_test]\n",
    "\n",
    "for file in train_files:\n",
    "    file_image = file.replace(\"imgs/\",\"\")\n",
    "    shutil.copy(path +file, path + \"train2017/\" + file_image)\n",
    "\n",
    "for file in valid_files:\n",
    "    file_image = file.replace(\"imgs/\",\"\")\n",
    "    shutil.copy(path +file, path + \"val2017/\" + file_image)\n",
    "\n",
    "for file in test_files:\n",
    "    file_image = file.replace(\"imgs/\",\"\")\n",
    "    shutil.copy(path +file, path + \"test2017/\" + file_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "dataset['info'] = []\n",
    "dataset[\"licenses\"] = []\n",
    "dataset['categories'] = []\n",
    "dataset[\"images\"] = []\n",
    "dataset['annotations'] = []\n",
    "\n",
    "\n",
    "# Info \n",
    "info = {}\n",
    "info[\"contributor\"] = \"Fruit Lab\"\n",
    "info[\"date_created\"] = '4/5/2020' \n",
    "info[\"description\"] = \"Hand Dataset Training\" \n",
    "info[\"url\"] = \"https://github.com/oggyfaker\"\n",
    "info[\"version\"] = \"7GB\"\n",
    "info[\"year\"] = \"2020\"\n",
    "dataset['info'].append(info)\n",
    "\n",
    "\n",
    "# License \n",
    "license = {} \n",
    "license['id'] = 1 \n",
    "license['name'] = \"Fruit Lab\"\n",
    "license['url'] = \"https://github.com/oggyfaker\"\n",
    "dataset[\"licenses\"].append(license)\n",
    "\n",
    "\n",
    "# Categories \n",
    "category = {}\n",
    "category['id'] = 1 \n",
    "category['name'] = \"hand\"\n",
    "category[\"supercategory\"] = \"body\"\n",
    "dataset['categories'].append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,data in enumerate(data_train):\n",
    "    # --------- Images ------------- \n",
    "    data_temp = {}\n",
    "    data_temp[\"id\"] = i \n",
    "    data_temp[\"width\"] = data['img_width'] \n",
    "    data_temp[\"height\"] = data['img_height']\n",
    "    \n",
    "    file_name = data['img_paths'].replace(\"imgs/\",\"\")\n",
    "    data_temp[\"file_name\"] = file_name\n",
    "    \n",
    "    data_temp[\"license\"] = 1 \n",
    "    data_temp[\"flickr_url\"] = \"\"\n",
    "    data_temp[\"coco_url\"] = \"\"\n",
    "    data_temp[\"date_captured\"] = \"15/5/2020\"\n",
    "    dataset[\"images\"].append(data_temp)\n",
    "    \n",
    "    # ---------- Annotations --------\n",
    "    tmp = {}\n",
    "    x_list = [item[0] for item in data['joint_self']]\n",
    "    y_list = [item[1] for item in data['joint_self']]\n",
    "    \n",
    "    x_min = min(x_list) - 25\n",
    "    y_min = min(y_list) - 15\n",
    "    \n",
    "    x_max = max(x_list) + 15\n",
    "    y_max = max(y_list) + 20\n",
    "    \n",
    "    width = x_max - x_min \n",
    "    height = y_max - y_min\n",
    "    \n",
    "    tmp['id'] = i \n",
    "    tmp[\"image_id\"] = i\n",
    "    tmp[\"category_id\"] = 1\n",
    "    tmp[\"segmentation\"] = [[]]\n",
    "    tmp[\"area\"] = width *  height\n",
    "    tmp[\"bbox\"] = [x_min,y_min,width,height] \n",
    "    tmp[\"iscrowd\"] = 0 # No more than 2 people\n",
    "    dataset['annotations'].append(tmp)\n",
    "\n",
    "import json\n",
    "with open(\"./Annotations/CMU2020_train.json\", \"w\") as outfile: \n",
    "    json.dump(dataset, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "dataset['info'] = []\n",
    "dataset[\"licenses\"] = []\n",
    "dataset['categories'] = []\n",
    "dataset[\"images\"] = []\n",
    "dataset['annotations'] = []\n",
    "\n",
    "\n",
    "# Info \n",
    "info = {}\n",
    "info[\"contributor\"] = \"Fruit Lab\"\n",
    "info[\"date_created\"] = '4/5/2020' \n",
    "info[\"description\"] = \"Hand Dataset Validation\" \n",
    "info[\"url\"] = \"https://github.com/oggyfaker\"\n",
    "info[\"version\"] = \"7GB\"\n",
    "info[\"year\"] = \"2020\"\n",
    "dataset['info'].append(info)\n",
    "\n",
    "\n",
    "# License \n",
    "license = {} \n",
    "license['id'] = 1 \n",
    "license['name'] = \"Fruit Lab\"\n",
    "license['url'] = \"https://github.com/oggyfaker\"\n",
    "dataset[\"licenses\"].append(license)\n",
    "\n",
    "\n",
    "# Categories \n",
    "category = {}\n",
    "category['id'] = 1 \n",
    "category['name'] = \"hand\"\n",
    "category[\"supercategory\"] = \"body\"\n",
    "dataset['categories'].append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,data in enumerate(data_valid):\n",
    "    # --------- Images ------------- \n",
    "    data_temp = {}\n",
    "    data_temp[\"id\"] = i \n",
    "    data_temp[\"width\"] = data['img_width'] \n",
    "    data_temp[\"height\"] = data['img_height']\n",
    "    \n",
    "    file_name = data['img_paths'].replace(\"imgs/\",\"\")\n",
    "    data_temp[\"file_name\"] = file_name\n",
    "    \n",
    "    data_temp[\"license\"] = 1 \n",
    "    data_temp[\"flickr_url\"] = \"\"\n",
    "    data_temp[\"coco_url\"] = \"\"\n",
    "    data_temp[\"date_captured\"] = \"15/5/2020\"\n",
    "    dataset[\"images\"].append(data_temp)\n",
    "    \n",
    "    # ---------- Annotations --------\n",
    "    tmp = {}\n",
    "    x_list = [item[0] for item in data['joint_self']]\n",
    "    y_list = [item[1] for item in data['joint_self']]\n",
    "    \n",
    "    x_min = min(x_list) - 25\n",
    "    y_min = min(y_list) - 15\n",
    "    \n",
    "    x_max = max(x_list) + 15\n",
    "    y_max = max(y_list) + 20\n",
    "    \n",
    "    width = x_max - x_min \n",
    "    height = y_max - y_min\n",
    "    \n",
    "    tmp['id'] = i \n",
    "    tmp[\"image_id\"] = i\n",
    "    tmp[\"category_id\"] = 1\n",
    "    tmp[\"segmentation\"] = [[]]\n",
    "    tmp[\"area\"] = width *  height\n",
    "    tmp[\"bbox\"] = [x_min,y_min,width,height] \n",
    "    tmp[\"iscrowd\"] = 0 # No more than 2 people\n",
    "    dataset['annotations'].append(tmp)\n",
    "\n",
    "import json\n",
    "with open(\"./Annotations/CMU2020_valid.json\", \"w\") as outfile: \n",
    "    json.dump(dataset, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "dataset['info'] = []\n",
    "dataset[\"licenses\"] = []\n",
    "dataset['categories'] = []\n",
    "dataset[\"images\"] = []\n",
    "dataset['annotations'] = []\n",
    "\n",
    "\n",
    "# Info \n",
    "info = {}\n",
    "info[\"contributor\"] = \"Fruit Lab\"\n",
    "info[\"date_created\"] = '4/5/2020' \n",
    "info[\"description\"] = \"Hand Dataset Testing\" \n",
    "info[\"url\"] = \"https://github.com/oggyfaker\"\n",
    "info[\"version\"] = \"7GB\"\n",
    "info[\"year\"] = \"2020\"\n",
    "dataset['info'].append(info)\n",
    "\n",
    "\n",
    "# License \n",
    "license = {} \n",
    "license['id'] = 1 \n",
    "license['name'] = \"Fruit Lab\"\n",
    "license['url'] = \"https://github.com/oggyfaker\"\n",
    "dataset[\"licenses\"].append(license)\n",
    "\n",
    "\n",
    "# Categories \n",
    "category = {}\n",
    "category['id'] = 1 \n",
    "category['name'] = \"hand\"\n",
    "category[\"supercategory\"] = \"body\"\n",
    "dataset['categories'].append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,data in enumerate(data_test):\n",
    "    # --------- Images ------------- \n",
    "    data_temp = {}\n",
    "    data_temp[\"id\"] = i \n",
    "    data_temp[\"width\"] = data['img_width'] \n",
    "    data_temp[\"height\"] = data['img_height']\n",
    "    \n",
    "    file_name = data['img_paths'].replace(\"imgs/\",\"\")\n",
    "    data_temp[\"file_name\"] = file_name\n",
    "    \n",
    "    data_temp[\"license\"] = 1 \n",
    "    data_temp[\"flickr_url\"] = \"\"\n",
    "    data_temp[\"coco_url\"] = \"\"\n",
    "    data_temp[\"date_captured\"] = \"15/5/2020\"\n",
    "    dataset[\"images\"].append(data_temp)\n",
    "    \n",
    "    # ---------- Annotations --------\n",
    "    tmp = {}\n",
    "    x_list = [item[0] for item in data['joint_self']]\n",
    "    y_list = [item[1] for item in data['joint_self']]\n",
    "    \n",
    "    x_min = min(x_list) - 25\n",
    "    y_min = min(y_list) - 15\n",
    "    \n",
    "    x_max = max(x_list) + 15\n",
    "    y_max = max(y_list) + 20\n",
    "    \n",
    "    width = x_max - x_min \n",
    "    height = y_max - y_min\n",
    "    \n",
    "    tmp['id'] = i \n",
    "    tmp[\"image_id\"] = i\n",
    "    tmp[\"category_id\"] = 1\n",
    "    tmp[\"segmentation\"] = [[]]\n",
    "    tmp[\"area\"] = width *  height\n",
    "    tmp[\"bbox\"] = [x_min,y_min,width,height] \n",
    "    tmp[\"iscrowd\"] = 0 # No more than 2 people\n",
    "    dataset['annotations'].append(tmp)\n",
    "\n",
    "import json\n",
    "with open(\"./Annotations/CMU2020_test.json\", \"w\") as outfile: \n",
    "    json.dump(dataset, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
